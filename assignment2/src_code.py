# -*- coding: utf-8 -*-
"""pred_def_payment.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1jZAsG3kGS1FK3Y5HHUqAdp3YLLUb1qzL
"""

#!pip install -U scipy
#!pip install -U keras_metrics
#!pip install -U imbalanced-learn
#!pip install -U pandas_profiling
#!pip install -U keras


from keras import *
import tensorflow as tf
import pandas as pd
import numpy as np
from sklearn.model_selection import train_test_split
from sklearn.metrics import mean_squared_error
import matplotlib.pyplot as plt
from keras.layers import Activation, LeakyReLU
from tensorflow.keras.activations import sigmoid
from keras.utils.generic_utils import get_custom_objects
from keras import backend as K
from sklearn.preprocessing import StandardScaler
import os 
import statistics

X_train = pd.read_csv("https://raw.githubusercontent.com/jimmypuntoexe/advanceML/master/assignment2/data/X_train.csv")
X_test = pd.read_csv("https://raw.githubusercontent.com/jimmypuntoexe/advanceML/master/assignment2/data/X_test.csv")
y_train = pd.read_csv("https://raw.githubusercontent.com/jimmypuntoexe/advanceML/master/assignment2/data/y_train.csv")

X_train.describe()

X_train.dtypes

y_train.describe()

"""**Correlation**"""

import matplotlib.pyplot as plt

correlation = X_train.corr('spearman')
f = plt.figure(figsize=(12, 12))
m = plt.matshow(correlation, fignum=f.number, cmap=plt.cm.coolwarm)
plt.xticks(range(X_train.shape[1]), X_train.columns, fontsize=10, rotation=90)
plt.yticks(range(X_train.shape[1]), X_train.columns, fontsize=10, rotation=0)
plt.colorbar(m, fraction=0.046, pad=0.04)
plt.show()

y_train['default.payment.next.month'].value_counts()

def preprocess_data(X, scaler=None):
    columns = X.columns
    """Preprocess input data by standardise features 
    by removing the mean and scaling to unit variance"""
    if not scaler:
        scaler = StandardScaler()
        scaler.fit(X)
    X[columns] = scaler.transform(X[columns])
    return X, scaler

print('Train dims', X_train.shape)
print('Test dims', X_test.shape)
print('Target dims', y_train.shape)

y_train.drop(['ID'], axis=1, inplace=True)
X_train.drop(['ID'], axis=1, inplace=True)
X_test.drop(['ID'], axis=1, inplace=True)
X_train.loc[X_train.EDUCATION > 5, "EDUCATION"] = 5

X_train.describe()

from imblearn.over_sampling import KMeansSMOTE

smote = KMeansSMOTE(sampling_strategy='minority', random_state=42, kmeans_estimator=30, cluster_balance_threshold=0.25)
x_over, y_over = smote.fit_resample(X_train.values, y_train.values)
over_train = pd.DataFrame(x_over, columns=X_train.columns)

y_train=pd.DataFrame(y_over, columns=['default.payment.next.month'])

y_train['default.payment.next.month'].value_counts()

X_train, scaler = preprocess_data(over_train)
test_final, _ = preprocess_data(X_test, scaler)

X_train, X_validation, y_train, y_validation = train_test_split(X_train, y_train, test_size=0.2, random_state=42)

print('Train dims', X_train.shape)
print('Test dims', X_test.shape)
print('Target dims', y_train.shape)

from tensorflow.keras import models
from tensorflow.keras import layers
from tensorflow.keras import optimizers
from keras.datasets import fashion_mnist
from keras.utils import np_utils
from keras.models import Sequential
from keras.layers.core import Dense, Dropout
from keras.optimizers import SGD
from sklearn.model_selection import train_test_split
from tensorflow.keras import regularizers
from keras.backend import abs, sum
import tensorflow as tf
import keras_metrics
initializer = tf.keras.initializers.GlorotUniform(seed=1234) 

def NeuralNetwork():
  dims = X_train.shape[1]
  
  #initial random wights seed because we see the changes make from regularization

  model = Sequential()
  model.add(Dense(256, input_shape=(dims,), activation = "relu", kernel_initializer=initializer))
  model.add(Dense(128, activation = "relu", kernel_initializer=initializer))
  model.add(Dense(32, activation = "relu", kernel_initializer=initializer))
  model.add(Dense(16, activation = "relu", kernel_initializer=initializer))
  model.add(Dense(1, activation = "sigmoid", kernel_initializer=initializer)) 


  model.compile(optimizer=SGD(lr=0.001), loss='binary_crossentropy',metrics=['accuracy', metrics.Precision(name='precision'), metrics.Recall(name='recall')])
  return model

model = NeuralNetwork()
model.summary()

print('Xval dims', X_validation.shape)
print('Yval dims', y_validation.shape)

n_epochs =90 
network_history = model.fit(X_train, y_train, batch_size=128, 
                            epochs=n_epochs, verbose=2, validation_data=(X_validation, y_validation))

x_plot = list(range(1,n_epochs+1))

def plot_history(network_history):
    plt.figure()
    plt.xlabel('Epochs')
    plt.ylabel('Loss')
    plt.plot(x_plot, network_history.history['loss'])
    plt.plot(x_plot, network_history.history['val_loss'])
    plt.legend(['Training', 'Validation'])

    plt.figure()
    plt.xlabel('Epochs')
    plt.ylabel('Accuracy')
    plt.plot(x_plot, network_history.history['accuracy'])
    plt.plot(x_plot, network_history.history['val_accuracy'])
    plt.legend(['Training', 'Validation'], loc='lower right')
    plt.show()

plot_history(network_history)

from sklearn.metrics import classification_report

print(classification_report(y_validation, model.predict_classes(X_validation)))

"""**Regularization**

**L1**
"""

def NeuralNetwork_l1():
  dims = X_train.shape[1]
  model_l1 = Sequential()
  model_l1.add(Dense(256, input_shape=(dims,), activation = "relu",kernel_initializer=initializer, kernel_regularizer=regularizers.l1(0.01)))
  model_l1.add(Dense(128, activation = "relu", kernel_initializer=initializer, kernel_regularizer=regularizers.l1(0.01)))
  model_l1.add(Dense(32, activation = "relu", kernel_initializer=initializer, kernel_regularizer=regularizers.l1(0.01)))
  model_l1.add(Dense(16, activation = "relu", kernel_initializer=initializer, kernel_regularizer=regularizers.l1(0.01)))
  model_l1.add(Dense(1, activation = "sigmoid", kernel_initializer=initializer))        


  model_l1.compile(optimizer=SGD(lr=0.001), loss='binary_crossentropy',metrics=['accuracy', metrics.Precision(name='precision'), metrics.Recall(name='recall')])

  
  return model_l1

model_l1 = NeuralNetwork_l1()
model_l1.summary()

network_history_l1 = model_l1.fit(X_train, y_train, batch_size=128, 
                              epochs=90, verbose=2, validation_data=(X_validation, y_validation))

x_plot = list(range(1,n_epochs+1))

def plot_history(network_history_l1):
    plt.figure()
    plt.xlabel('Epochs')
    plt.ylabel('Loss')
    plt.plot(x_plot, network_history_l1.history['loss'])
    plt.plot(x_plot, network_history_l1.history['val_loss'])
    plt.legend(['Training', 'Validation'])

    plt.figure()
    plt.xlabel('Epochs')
    plt.ylabel('Accuracy')
    plt.plot(x_plot, network_history_l1.history['accuracy'])
    plt.plot(x_plot, network_history_l1.history['val_accuracy'])
    plt.legend(['Training', 'Validation'], loc='lower right')
    plt.show()

plot_history(network_history_l1)

from sklearn.metrics import classification_report

print(classification_report(y_validation, model_l1.predict_classes(X_validation)))

"""**L2**"""

def NeuralNetwork_L2():
  dims = X_train.shape[1]
  model_l2 = Sequential()
  model_l2.add(Dense(256, input_shape=(dims,), activation = "relu", kernel_initializer=initializer, kernel_regularizer=regularizers.l2(0.01) ))
  model_l2.add(Dense(128, activation = "relu", kernel_initializer=initializer, kernel_regularizer=regularizers.l2(0.01) ))
  model_l2.add(Dense(32, activation = "relu", kernel_initializer=initializer, kernel_regularizer=regularizers.l2(0.01) ))
  model_l2.add(Dense(16, activation = "relu", kernel_initializer=initializer, kernel_regularizer=regularizers.l2(0.01) ))
  model_l2.add(Dense(1, activation = "sigmoid",kernel_initializer=initializer))

  model_l2.compile(optimizer=SGD(lr=0.001), loss='binary_crossentropy',metrics=['accuracy', metrics.Precision(name='precision'),  metrics.Recall(name='recall')])


  return model_l2

model_l2 = NeuralNetwork_L2()
model_l2.summary()

network_history_l2 = model_l2.fit(X_train, y_train, batch_size=128, 
                              epochs=90, verbose=2, validation_data=(X_validation, y_validation))

x_plot = list(range(1,n_epochs+1))

def plot_history(network_history_l2):
    plt.figure()
    plt.xlabel('Epochs')
    plt.ylabel('Loss')
    plt.plot(x_plot, network_history_l2.history['loss'])
    plt.plot(x_plot, network_history_l2.history['val_loss'])
    plt.legend(['Training', 'Validation'])

    plt.figure()
    plt.xlabel('Epochs')
    plt.ylabel('Accuracy')
    plt.plot(x_plot, network_history_l2.history['accuracy'])
    plt.plot(x_plot, network_history_l2.history['val_accuracy'])
    plt.legend(['Training', 'Validation'], loc='lower right')
    plt.show()

plot_history(network_history_l2)

from sklearn.metrics import classification_report

print(classification_report(y_validation, model_l2.predict_classes(X_validation)))

"""**Weight Control**"""

print('Layers name:', model.weights[6].name)
print('Layers kernel shape:', model.weights[6].shape)
print('Kernel:', model.weights[6][0], end = '\n\n')
print('Layers name:', model.weights[7].name)
print('Layers kernel shape:', model.weights[7].shape)
print('Kernel:', model.weights[7])

print('Layers name:', model_l2.weights[6].name)
print('Layers kernel shape:', model_l2.weights[6].shape)
print('Kernel:', model_l2.weights[6][0], end = '\n\n')
print('Layers name:', model_l2.weights[7].name)
print('Layers kernel shape:', model_l2.weights[7].shape)
print('Kernel:', model_l2.weights[7])

print('Layers name:', model_l1.weights[6].name)
print('Layers kernel shape:', model_l1.weights[6].shape)
print('Kernel:', model_l1.weights[6][0], end = '\n\n')
print('Layers name:', model_l1.weights[7].name)
print('Layers kernel shape:', model_l1.weights[7].shape)
print('Kernel:', model_l1.weights[7])

print('Sum of the values of the weights without regularization:', sum(abs(model.weights[6][0])).numpy() + sum(abs(model.weights[7][0])).numpy())
print('Sum of the values of the weights with regularization l2:', sum(abs(model_l2.weights[6][0])).numpy() + sum(abs(model_l2.weights[7][0])).numpy())
print('Sum of the values of the weights with regularization l1:', sum(abs(model_l1.weights[6][0])).numpy() + sum(abs(model_l1.weights[7][0])).numpy())

"""**Dropout**"""

initializer = tf.keras.initializers.GlorotUniform(seed=1234)

def NeuralNetwork_Drop():
  dims = X_train.shape[1]
  model_d = Sequential()
  model_d.add(Dense(256, input_shape=(dims,), activation = "relu", kernel_initializer=initializer))
  model_d.add(Dense(128, activation = "relu", kernel_initializer=initializer))
  model_d.add(Dropout(0.2))
  model_d.add(Dense(32, activation = "relu", kernel_initializer=initializer))
  model_d.add(Dropout(0.2))
  model_d.add(Dense(16, activation = "relu", kernel_initializer=initializer))
  model_d.add(Dropout(0.2))
  model_d.add(Dense(1, activation = "sigmoid", kernel_initializer=initializer))


  model_d.compile(optimizer=SGD(lr=0.001), loss='binary_crossentropy',metrics=['accuracy', metrics.Precision(name='precision'),  metrics.Recall(name='recall')])
  return model_d

model_drop = NeuralNetwork_Drop()
model_drop.summary()
n_epochs = 90

network_history_model_drop = model_drop.fit(X_train, y_train, batch_size=128, 
                            epochs=n_epochs, verbose=2, validation_data=(X_validation, y_validation))

x_plot = list(range(1,n_epochs+1))

def plot_history(network_history_model_drop):
    plt.figure()
    plt.xlabel('Epochs')
    plt.ylabel('Loss')
    plt.plot(x_plot, network_history_model_drop.history['loss'])
    plt.plot(x_plot, network_history_model_drop.history['val_loss'])
    plt.legend(['Training', 'Validation'])

    plt.figure()
    plt.xlabel('Epochs')
    plt.ylabel('Accuracy')
    plt.plot(x_plot, network_history_model_drop.history['accuracy'])
    plt.plot(x_plot, network_history_model_drop.history['val_accuracy'])
    plt.legend(['Training', 'Validation'], loc='lower right')
    plt.show()

plot_history(network_history_model_drop)

print(classification_report(y_validation, model_drop.predict_classes(X_validation)))

print('Sum of the values of the weights with dropout:', sum(abs(model_drop.weights[6][0])).numpy() + sum(abs(model_drop.weights[7][0])).numpy())

"""**Best Model**"""

y_predict = (model_l2.predict(test_final))
y_predict

np.savetxt(f'Gianmaria_Balducci_807141_score.txt', y_predict, fmt='%1.0f')

